install.packages("earlywarnings")
install.packages("R.matlab")
??detrending
??qda_ews
x = 1
y = 2
a, b <- (x+y, x-y)
c(a,b)<- c(x+y,x-y)
library(R.matlab)
CurrentTs <- readMat("C:\\Users\\user\\Desktop\\URECA\\URECA 2013-2014\\Precursors forecasting\\ToBeA2.mat")
CurrentTS
a <- CurrentTS(1:4306)
info(CurrentTs)
CurrentTs
a <- CurrentTs(1:4306)
a <- CurrentTs[1:4306]
a
shape(a)
size(a)
dim(a)
CurrentTs[1]
a <- CurrentTs[1]
dim(a)
a
len(a)
a[1]
a[3303,]
a[3303,1]
max(a)
b <- data.matrix(a)
dim(b)
b
b <- data.matrix(CurrentTs)
b
c <- read.csv("C:\\Users\\user\\Desktop\\URECA\\URECA 2013-2014\\Precursors forecasting\\Current Time Series.csv")
c
dim(c)
c[1]
c[1,1]
c[4305,1]
x <- 1:4305
d <- read.csv("C:\\Users\\user\\Desktop\\URECA\\URECA 2013-2014\\Precursors forecasting\\Current Time Series.csv", header=FALSE)
View(c)
View(d)
c <- d
d <- ksmooth(x, c, kernel="normal", bandwidth=0.5)
dim(c)
dim(d)
dim(x)
x <- c(1:4306)
dim(x)
x <- array(1:4306,4306)
dim(x)
x <- matrix(1:4306,4306,1)
dim(x)
d <- ksmooth(x, c, kernel="normal", bandwidth=0.5)
library(gdata)
install.packages("gdata")
library(gdata)
install.packages("perl")
install.packages("XLConnect")
library(XLConnect)
install.packages("plyr")
install.packages("ggplot2")
library(plyr)
library(ggplot2)
install.packages("lubridate")
library(lubridate)
install.packages('KernSmooth')
library(KernSmooth)
source("http://www.openintro.org/stat/data/present.R")
present
View(present)
present$boys
plot(x = present$year, y = present$girls)
plot(x = present$year, y = present$girls, type = "l")
?plot
present$boys + present$girls
plot(present$year, present$boys + present$girls, type = "l")
max(present$boys + present$girls)
?max
plot(present$year, present$boys / (present$boys + present$girls), type = "l")
present$boys > present$girls
plot(present$year, present$boys / present$girls, type = "l")
abs(-100)
abs(present$boys - present$girls)
max(abs(present$boys - present$girls))
source("http://www.openintro.org/stat/data/cdc.R")
names(cdc)
View(cdc)
summary(cdc$weight)
table(cdc$smoke100)
table(cdc$smoke100)/20000
barplot(table(cdc$smoke100))
table(cdc$gender)
table(cdc$genhlth)/20000
gender_smokers = table(cdc$gender,cdc$smoke100)
gender_smokers
mosaicplot(gender_smokers)
dim(cdc)
cdc[567,6]
1:10
cdc[1:10,]
mdata = subset(cdc, cdc$gender == "m")
head(mdata)
under23_and_smoke = subset(cdc, cdc$age < 23 & cdc$smoke100 == 1)
boxplot(cdc$height)
summary(cdc$height)
boxplot(cdc$height ~ cdc$gender)
bmi = (cdc$weight / cdc$height^2) * 703
boxplot(bmi ~ cdc$genhlth)
summary(bmi)
hist(cdc$age)
hist(bmi)
hist(bmi, breaks = 50)
plot(cdc$weight, cdc$wtdesire)
load(url("http://www.openintro.org/stat/data/kobe.RData"))
head(kobe)
kobe$basket[1:9]
kobe_streak <- calc_streak(kobe$basket)
barplot(table(kobe_streak))
barplot(table(kobe_streak)/76)
summary(table(kobe_streak))
summary(kobe_streak)
outcomes <- c("heads", "tails")
sample(outcomes, size = 1, replace = TRUE)
sim_fair_coin <- sample(outcomes, size = 100, replace = TRUE)
table(sim_fair_coin)
sim_unfair_coin <- sample(outcomes, size = 100, replace = TRUE, prob = c(0.2,0.8))
table(sim_unfair_coin)
outcomes <- c("H","M")
sim_basket <- sample(outcomes, size = 133, replace = TRUE, prob = c(0.45,0.55))
kobe$basket
sim_basket
sim_streak <- calc_streak(sim_basket)
table(sim_streak)
barplot(table(sim_streak))
barplot(table(sim_streak)/77)
table(kobe_streak)
load(url("http://bit.ly/dasi_gss_data"))
names(gss)
table(gss$natpark)
table(gss$income06)
table(gss$confinan)
gss_analysis <- c(gss$caseid, gss$income06, gss$confinan)
gss_analysis <- table(gss$caseid, gss$income06, gss$confinan)
gss_analysis <- table(gss$income06, gss$confinan)
gss_analysis
head(gss)
myvar <- c("caseid","income06", "confinan")
gss_subset <- gss(myvar)
gss_subset <- gss[myvar]
head(gss_subset)
gss_subset <- subset(gss_subset, gss_subset$income06 ~= "<NA>" && gss_subset$confinan ~= "<NA>")
gss_subset <- subset(gss_subset, gss_subset$income06 != "<NA>" && gss_subset$confinan != "<NA>")
barplot(gss_analysis)
gss_analysis <- table(gss$confinan, gss$income06)
barplot(gss_analysis)
mosaicplot(gss_analysis)
gss_analysis <- table(gss$income06, gss$confinan)
mosaicplot(gss_analysis)
gss_analysis <- table(gss$confinan, gss$income06)
gss_subset <- gss[myvar]
na.omit(gss_subset)
gss_subset <- na.omit(gss_subset)
head(gss_subset)
gss_subset[1:100,]
library(xlsx)
download.packages("xlsx")
download.packages(xlsx)
install.packages("xlsx")
install.packages("XML")
install.packages("jsonlite")
install.packages(c("manipulate", "plyr", "Rcpp", "scales", "stringi"))
load(url("http://www.openintro.org/stat/data/ames.RData"))
names(ames)
load(url("http://www.openintro.org/stat/data/ames.RData"))
area <- ames$Gr.Liv.Area
price <- ames$SalePrice
summary(area)
hist(area)
samp0 <- sample(area, 50)
samp1 <- sample(area, 50)
mean(samp1)
mean(samp0)
sample_means50 <- rep(NA, 5000)
for(i in 1:5000){}
for(i in 1:5000){
samp <- sample(area,50)
sample_means50[i] <- mean(samp)
}
hist(sample_means50)
hist(sample_means50, breaks = 25)
sample_means_small = rep(NA, 100)
for(i in 1:100){
samp <- sample(area,50)
sample_means_small[i] <- mean(samp)
}
sample_means_small
sample_means10 <- rep(NA, 5000)
sample_means100 <- rep(NA, 5000)
for(i in 1:5000){
samp <- sample(area, 10)
sample_means10[i] <- mean(samp)
samp <- sample(area, 100)
sample_means100[i] <- mean(samp)
}
par(mfrow = c(3,1))
xlimits = range(sample_means10)
hist(sample_means10, breaks = 20, xlim = xlimits)\
hist(sample_means10, breaks = 20, xlim = xlimits)
hist(sample_means50, breaks = 20, xlim = xlimits)
hist(sample_means100, breaks = 20, xlim = xlimits)
par(mfrow = c(1,1))
sample_means50 <- rep(NA, 5000)
sample_means150 <- rep(NA, 5000)
for(i in 1:5000){
samp <- sample(area, 50)
sample_means50[i] <- mean(samp)
samp <- sample(area, 150)
sample_means150[i] <- mean(samp)
}
par(mfrow = c(2,1))
xlimits = range(sample_means50)
hist(sample_means50, breaks = 20, xlim = xlimits)
hist(sample_means150, breaks = 20, xlim = xlimits)
population <- ames$Gr.Liv.Area
samp <- sample(population, 60)
hist(samp)
par(mfrow = c(1,1))
hist(samp)
sample_mean <- mean(samp)
se <- sd(samp)/sqrt(60)
lower <- sample_mean - 1.96 * se
upper <- sample_mean + 1.96 * se
c(lower, upper)
mean(population)
samp_mean <- rep(NA, 50)
samp_sd <- rep(NA, 50)
n <- 60
for(i in 1:50){
samp <- sample(population, n)
samp_mean[i] <- mean(samp)
samp_sd[i] <- sd(samp)
}
lower <- samp_mean - 1.96 * samp_sd / sqrt(n)
upper <- samp_mean + 1.96 * samp_sd / sqrt(n)
c(lower[1], upper[1])
plot_ci(lower, upper, mean(population))
ques1 <- read.csv("quiz1data.csv")
ques1$FES
library(xlsx)
library(xlsx)
install.packages("rJava")
library(xlsx)
install.packages("xlsx")
library(xlsx)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
library(XML)
doc <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", "quiz1data3.xml")
fileUrl <- "quiz1data3.xml"
doc <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
rootNode <- xmlRoot(doc)
library(xlsx)
quiz1data2 <- read.table("quiz1data2.xlsx")
quiz1data2 <- read.xlsx("quiz1data2.xlsx", sheetIndex = 1, header = TRUE)
library(rJava)
Sys.getenv("JAVA_HOME")
Sys.setenv(JAVA_HOME="C:\\Program Files (x86)\\Java\\jre1.8.0_51")
Sys.getenv("JAVA_HOME")
library(xlsx)
library(rJava)
install.packages(rJava)
install.packages("rJava")
library(xlsx)
library(xlsx)
install.packages('rJava', .libPaths()[1], 'http://www.rforge.net/')
library(xlsx)
library(rJava)
install.packages("rJava")
Sys.setenv(JAVA_HOME="")
library(rJava)
install.packages("xlsx")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "quiz1data4.csv")
library(data.table)
install.packages("data.table")
library(data.table)
fread("quiz1data4.csv")
ques5 <- fread("quiz1data4.csv")
names(ques5)
ques1 <- fread("quiz1data.csv")
ques1$VAL
ques1$VAL == 24
ques1 <- read.table("ques1data.csv", sep=",")
ques1 <- read.table("quiz1data.csv", sep=",")
ques1 <- read.csv("quiz1data.csv", sep=",")
install.packages("openxlsx")
library(openxlsx)
View(ques1)
ques1 <- read.csv("quiz1data.csv")
bad <- is.na(ques1$VAL)
ques1_v2 <- ques1[!bad,]
ques1_v3 <- ques1[ques1$VAL == 24,]
ques1_v3 <- ques1_V2[ques1_v2$VAL == 24,]
ques1_v3 <- ques1_v2[ques1_v2$VAL == 24,]
ques3 <- read.xlsx("quiz1data2.xlsx")
?"openxlsx"
ques3 <- read.xlsx("quiz1data2.xlsx", sheet=1, rows=18:23, cols=7:15)
ques3 <- read.xlsx("quiz1data2.xlsx", sheet=1, rows=18:23, cols=7:15)
dat <- ques3
dat
sum(dat$Zip*dat$Ext, na.rm=T)
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
doc <- xmlTreeParse(fileUrl)
doc <- xmlParse(fileUrl)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileURL, destfile=tf <- tempfile(fileext=".xml"))
doc <- xmlParse(tf)
zip <- xpathSApply(doc, "/response/row/row/zipcode", xmlValue)
sum(zip == 21231)
ques1 <- fread("quiz1data.csv")
ques1$FES
table(ques1$FES)
?read.csv
install.packages("httr")
content(req)
data = content(req)
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
key = "a4280c34e0d2621a0f37",
secret = "4168939fe533c868437e6f59c1d02a6b885a91d0")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
exit
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", key = "a4280c34e0d2621a0f37", secret = "4168939fe533c868437e6f59c1d02a6b885a91d0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
exit
install.packages("httpuv")
library(httr)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
data = content(req)
data
data[[1]]$name
data[[2]]$name
data[[3]]$name
data[[4]]$name
data[[5]]$name
data[[6]]$name
data[[7]]$name
data[[7]]$created_at
install_packages("sqldf")
install.packages("sqldf")
install.packages("devtools")
library(devtools)
find_rtools()
?sqldf
con = url("http://biostat.jhsph.edu/~jleek/contact.htm")
htmlCode = readLines(con)
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
htmlCode = readLines(con)
?readLines
htmlCode[10]
htmlCode[10].nchar()
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
library(utils)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for")
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 9)
View(a)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 20)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 100)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 15)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 19)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 22)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 24)
a <- read.fwf("D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", 23)
a[1]
a[[1]]
a[1][1]
a <- read.fwf(file = "D://Coursera - Data Science//Getting and Cleaning Data//Week 2 Lectures//getdata-wksst8110.for", skip=4, widths=c(12, 7,4, 9,4, 9,4, 9,4, 9,4))
head(a)
sum(a$V4)
library(datasets)
data(iris)
?iris
tapply(iris$Sepal.Length, iris$Species == "virginica", mean)
library(datasets)
data(mtcars)
?mtcars
summary(mtcars$cyl)
table(mtcars$cyl)
?tapply
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
c <- tapply(mtcars$hp, mtcars$cyl, mean)
c[1]
c[3] - c[1]
?debug
makeCacheMatrix <- function(x = matrix()) {
n <- NULL
set <- function(y) {
x <<- y
n <<- NULL
}
get <- function() x
setinv <- function(solve) n <<- solve
getinv <- function() n
list(set = set, get = get,
setinv = setinv, getinv = getinv)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
n <- x$getinv()
if(!is.null(n)) {
message("getting cached data")
return(n)
}
data <- x$get()
n <- solve(data, ...)
x$setmean(n)
n
}
A = matrix([4,2,7,6], 2, 2)
A = matrix(c(4,2,7,6), 2, 2)
A
B <- makeCacheMatrix(A)
cacheSolve(B)
cacheSolve(A)
cacheSolve(B)
cacheSolve(B)
B
cacheSolve(B, A)
B$get()
cacheSolve(B)
B$getinv()
solve(B$get())
B$setinv()
B$setinv(solve(B$get()))
B
B$getinv()
debug(cacheSolve)
cacheSolve(B)
x$setinv(n)
exit
0
exit
cacheSolve(B)
cacheSolve(B)
n
source('D:/Coursera - Data Science/R Programming/ProgrammingAssignment2/ProgrammingAssignment2/cachematrix.R')
cacheSolve(B)
setwd("D:/Coursera - Data Science/Getting and Cleaning Data/Project")
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
setwd("D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject")
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
?grepl
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
warnings()
avg_data_activity <- lapply(split(cleaned_data[,-(1:2)], cleaned_data$activity), mean, 2)
avg_data_subject <- lapply(split(cleaned_data[,-(1:2)], cleaned_data$subject), mean, 2)
A <- split(cleaned_data, cleaned_data$subject)
remove(Y_test)
?lapply
?mean
avg_data_activity <- lapply(split(cleaned_data[,-(1:2)], cleaned_data$activity), colMeans, na.rm = TRUE)
remove(A)
avg_data_subject <- lapply(split(cleaned_data[,-(1:2)], cleaned_data$subject), colMeans, na.rm = TRUE)
B <- rbind(avg_data_activity)
View(B)
remove(B)
?apply
?lapply
avg_data_subject <- lapply(split(cleaned_data[,-(1:2)], cleaned_data$subject), colMeans, na.rm = TRUE, simplify = TRUE)
avg_data_subject <- lapply(split(cleaned_data[,-(1:2)], cleaned_data$subject), simplify = TRUE, colMeans, na.rm = TRUE)
?data.frame
B <- data.frame(avg_data_activity)
View(B)
?write.table
source('D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/run_analysis.R')
View(cleaned_data)
View(avg_data_activity)
View(avg_data_subject)
?codebook
install.package("memisc")
install.packages("memisc")
?codebook
save.image("D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/backup.RData")
load("D:/Coursera - Data Science/Getting and Cleaning Data/Project/Github/CleaningDataProject/backup.RData")
